{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTVOQpMfhgLM"
      },
      "source": [
        "Esté um notebook Colab contendo exercícios de programação em python, numpy e pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMoyGt5gXMgK"
      },
      "source": [
        "## Coloque seu nome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBHbXcibXPRe",
        "outputId": "f4a3d646-5031-4f60-e3b1-2cf7d9177938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é: Matheus Lindino\n"
          ]
        }
      ],
      "source": [
        "print('Meu nome é: Matheus Lindino')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9S5acRbm1Zr"
      },
      "source": [
        "# Parte 1:\n",
        "\n",
        "##Exercícios de Processamento de Dados\n",
        "\n",
        "Nesta parte pode-se usar as bibliotecas nativas do python como a `collections`, `re` e `random`. Também pode-se usar o NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxS5h1V8nDn6"
      },
      "source": [
        "##Exercício 1.1\n",
        "Crie um dicionário com os `k` itens mais frequentes de uma lista.\n",
        "\n",
        "Por exemplo, dada a lista de itens `L=['a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a']` e `k=2`, o resultado deve ser um dicionário cuja chave é o item e o valor é a sua frequência: {'a': 4, 'e': 3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT08b5Z_nC-j"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "def top_k(L, k):\n",
        "  frequency = collections.Counter(L)\n",
        "  sort_orders = sorted(frequency.items(), key=lambda x: x[1], reverse=True)\n",
        "  return dict(sort_orders[0:k])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD_e3C9p4xO"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma entrada com poucos itens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMW9NiBgnkvA",
        "outputId": "62ffc5af-ca3b-4a56-9beb-69f4d1069543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resultado: {'a': 4, 'd': 3, 'e': 3}\n"
          ]
        }
      ],
      "source": [
        "L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n",
        "k = 3\n",
        "resultado = top_k(L=L, k=k)\n",
        "print(f'resultado: {resultado}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBeqZScQqJ0a"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma entrada com 10M de itens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_lhcm4ko8bY"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "L = random.choices('abcdefghijklmnopqrstuvwxyz', k=10_000_000)\n",
        "k = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9U-Bgs2o-f_",
        "outputId": "f7e9694a-1685-41b7-b09a-5629a6b2d78f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "476 ms ± 49.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "resultado = top_k(L=L, k=k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJHDaOz_tK38"
      },
      "source": [
        "## Exercício 1.2\n",
        "\n",
        "Em processamento de linguagem natural, é comum convertemos as palavras de um texto para uma lista de identificadores dessas palavras. Dado o dicionário `V` abaixo onde as chaves são palavras e os valores são seus respectivos identificadores, converta o texto `D` para uma lista de identificadores.\n",
        "\n",
        "Palavras que não existem no dicionário deverão ser convertidas para o identificador do token `unknown`.\n",
        "\n",
        "O código deve ser insensível a maiúsculas (case-insensitive).\n",
        "\n",
        "Se atente que pontuações (vírgulas, ponto final, etc) também são consideradas palavras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVzv89trtTPc"
      },
      "outputs": [],
      "source": [
        "def tokens_to_ids(text, vocabulary):\n",
        "  strings = D.lower().replace('.', ' .').split(' ')\n",
        "  result = []\n",
        "  for i in strings:\n",
        "    try:\n",
        "      result.append(V[i])\n",
        "    except:\n",
        "      result.append(V['unknown'])\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCGZeiqkY-sm"
      },
      "source": [
        "Mostre que sua implementação esta correta com um exemplo pequeno:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iApR1h7gY98E",
        "outputId": "4b01f38e-5d12-4a83-e314-23cd8877c28c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 2, 4, -1, 5]\n"
          ]
        }
      ],
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = 'Eu gosto de comer pizza.'\n",
        "\n",
        "print(tokens_to_ids(D, V))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWtTMxlXZN25"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxT_g-ZxZUsX"
      },
      "outputs": [],
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = ' '.join(1_000_000 * ['Eu gosto de comer pizza.'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp1nataGZU-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d513bd9a-fda1-4cf3-e647-5e2ec6d67cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.37 s ± 882 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "resultado = tokens_to_ids(D, V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfaKfXwRXn_"
      },
      "source": [
        "## Exercício 1.3\n",
        "\n",
        "Em aprendizado profundo é comum termos que lidar com arquivos muito grandes.\n",
        "\n",
        "Dado um arquivo de texto onde cada item é separado por `\\n`, escreva um programa que amostre `k` itens desse arquivo aleatoriamente.\n",
        "\n",
        "Nota 1: Assuma amostragem de uma distribuição uniforme, ou seja, todos os itens tem a mesma probablidade de amostragem.\n",
        "\n",
        "Nota 2: Assuma que o arquivo não cabe em memória.\n",
        "\n",
        "Nota 3: Utilize apenas bibliotecas nativas do python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PsadE9SRG_9"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def get_total_lines(fp):\n",
        "  count = 0\n",
        "  for i in fp:\n",
        "    count += 1\n",
        "  fp.seek(1)\n",
        "  return count\n",
        "\n",
        "def binary_search(A, item):\n",
        "    left, right = 0, len(A) - 1\n",
        "    while left <= right:\n",
        "        half = (left + right) // 2\n",
        "        if A[half] == item:\n",
        "            return half\n",
        "        elif A[half] > item:\n",
        "            right = half - 1\n",
        "        else:\n",
        "            left = half + 1\n",
        "    return -1\n",
        "\n",
        "def sample(path: str, k: int):\n",
        "  fp = open(path, 'r')\n",
        "  lines = []\n",
        "  total = get_total_lines(fp)\n",
        "  idx_lines = random.sample(range(total), k)\n",
        "  idx_lines.sort()\n",
        "\n",
        "  for index, line in enumerate(fp):\n",
        "    if binary_search(idx_lines, index) != -1:\n",
        "        lines.append(line.strip())\n",
        "        idx_lines.remove(index)\n",
        "\n",
        "  fp.close()\n",
        "  return lines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycEnlFWxSt0i"
      },
      "source": [
        "Mostre que sua implementação está correta com um exemplo pequeno:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyLJ1e2ZSzC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27412926-73ae-4d9a-8569-6e0d031bb828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['line 10', 'line 14', 'line 17', 'line 32', 'line 52', 'line 66', 'line 80', 'line 86', 'line 89', 'line 90']\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "filename = 'small.txt'\n",
        "total_size = 100\n",
        "n_samples = 10\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))\n",
        "\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "print(samples)\n",
        "print(len(samples) == n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r4FMiMj12Xg"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUwnNMGg18Ty"
      },
      "outputs": [],
      "source": [
        "filename = 'large.txt'\n",
        "total_size = 1_000_000\n",
        "n_samples = 10000\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA9sAZmo0UDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe354ce9-7803-4e06-df2c-889d1017b9e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.79 s ± 19.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "assert len(samples) == n_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udS0Ns4etoJs"
      },
      "source": [
        "# Parte 2:\n",
        "\n",
        "##Exercícios de Numpy\n",
        "\n",
        "Nesta parte deve-se usar apenas a biblioteca NumPy. Aqui não se pode usar o PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcMz3Vzjt144"
      },
      "source": [
        "##Exercício 2.1\n",
        "\n",
        "Quantos operações de ponto flutuante (flops) de soma e de multiplicação tem a multiplicação matricial $AB$, sendo que a matriz $A$ tem tamanho $m \\times n$ e a matriz $B$ tem tamanho $n \\times p$?:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNXj45RJqUm"
      },
      "source": [
        "**Resposta:**\n",
        "\n",
        "Para calcular o produto escalar, requer $n$ multiplicações e $n-1$ somas. Portanto:\n",
        "\n",
        "- número de somas: $m \\times (n-1) \\times p$ \n",
        "- número de multiplicações: $m \\times n \\times p$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iI7udBFeDlP"
      },
      "source": [
        "## Exercício 2.2\n",
        "\n",
        "Em programação matricial, não se faz o loop em cada elemento da matriz,\n",
        "mas sim, utiliza-se operações matriciais.\n",
        "\n",
        "Dada a matriz `A` abaixo, calcule a média dos valores de cada linha sem utilizar laços explícitos.\n",
        "\n",
        "Utilize apenas a biblioteca numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjrXf18N5KrK"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fqxgNBW27Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a741ed-2c38-4497-cb3f-8a5605883915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]]\n"
          ]
        }
      ],
      "source": [
        "A = np.arange(24).reshape(4, 6)\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am9-w8__EtQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0286b54f-ef32-4bc4-a9fe-685fea0a33f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.5,  8.5, 14.5, 20.5])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "A.mean(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtgSAAKjUfcO"
      },
      "source": [
        "## Exercício 2.3\n",
        "\n",
        "Seja a matriz $C$ que é a normalização da matriz $A$:\n",
        "$$ C(i,j) = \\frac{A(i,j) - A_{min}}{A_{max} - A_{min}} $$\n",
        "\n",
        "Normalizar a matriz `A` do exercício acima de forma que seus valores fiquem entre 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pDhb2-0eDlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a78a9a41-86d5-4387-e980-4e870e7c68e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.04347826 0.08695652 0.13043478 0.17391304 0.2173913 ]\n",
            " [0.26086957 0.30434783 0.34782609 0.39130435 0.43478261 0.47826087]\n",
            " [0.52173913 0.56521739 0.60869565 0.65217391 0.69565217 0.73913043]\n",
            " [0.7826087  0.82608696 0.86956522 0.91304348 0.95652174 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "C = (A - A.min()) / (A.max() - A.min())\n",
        "print(C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF_P_GARU62m"
      },
      "source": [
        "## Exercício 2.4\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *coluna* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras colunas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NgVzFOYeDla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e20f9079-0e47-468c-dd7c-6a7993e083d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.        ]\n",
            " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333]\n",
            " [0.66666667 0.66666667 0.66666667 0.66666667 0.66666667 0.66666667]\n",
            " [1.         1.         1.         1.         1.         1.        ]]\n"
          ]
        }
      ],
      "source": [
        "C = (A - A.min(axis=0)) / (A.max(axis=0) - A.min(axis=0))\n",
        "print(C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbXIXsDIUmtp"
      },
      "source": [
        "## Exercício 2.5\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *linha* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras linhas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gSU2p4mF1fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f9c424-c58e-4120-dc68-9377cf4f4e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]]\n"
          ]
        }
      ],
      "source": [
        "A = A.T\n",
        "C = ((A - A.min(axis=0)) / (A.max(axis=0) - A.min(axis=0))).T\n",
        "print(C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKnLAyL7zgpa"
      },
      "source": [
        "## Exercício 2.6\n",
        "\n",
        "A [função softmax](https://en.wikipedia.org/wiki/Softmax_function) é bastante usada em apredizado de máquina para converter uma lista de números para uma distribuição de probabilidade, isto é, os números ficarão normalizados entre zero e um e sua soma será igual à um.\n",
        "\n",
        "Implemente a função softmax com suporte para batches, ou seja, o softmax deve ser aplicado a cada linha da matriz. Deve-se usar apenas a biblioteca numpy. Se atente que a exponenciação gera estouro de representação quando os números da entrada são muito grandes. Tente corrigir isto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA5W9vxNEmOj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(A):\n",
        "  '''\n",
        "  Aplica a função de softmax à matriz `A`.\n",
        "\n",
        "  Entrada:\n",
        "    `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n",
        "    independentemente e N é o tamanho de cada exemplo.\n",
        "  \n",
        "  Saída:\n",
        "    Uma matriz M x N, onde a soma de cada linha é igual a um.\n",
        "  '''\n",
        "  T = A.T\n",
        "  exp = np.exp((T - T.max(axis=0)))\n",
        "  return (exp / exp.sum(axis=0)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpxlbh4ND54q"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma matriz pequena como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6EZ5ZD7HFao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "755e8ae1-0407-487a-87b4-40ca7f152476"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 1.        ],\n",
              "       [0.04861082, 0.35918811, 0.59220107]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "A = np.array([[0.5, -1, 1000],\n",
        "              [-2,   0, 0.5]])\n",
        "softmax(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j2uXmKH8HF4"
      },
      "source": [
        "O código a seguir verifica se sua implementação do softmax está correta. \n",
        "- A soma de cada linha de A deve ser 1;\n",
        "- Os valores devem estar entre 0 e 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-sN4STk7qyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2826c3e7-9ee7-4e45-d197-ed0b281cc760"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "np.allclose(softmax(A).sum(axis=1), 1) and softmax(A).min() >= 0 and softmax(A).max() <= 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5_ZRWRfCZtI"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhUeyrGaJ3J2"
      },
      "outputs": [],
      "source": [
        "A = np.random.uniform(low=-10, high=10, size=(128, 100_000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaa-C8XkKJin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9525346f-2e14-4fa8-cac8-202da538cd27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "253 ms ± 4.34 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "softmax(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XE6LaWi81zZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5edb01-a210-41a9-d690-c2e478ab061f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "SM = softmax(A)\n",
        "np.allclose(SM.sum(axis=1), 1) and SM.min() >= 0 and SM.max() <= 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flr1lI5o-HpG"
      },
      "source": [
        "## Exercício 2.7\n",
        "\n",
        "A codificação one-hot é usada para codificar entradas categóricas. É uma codificação onde apenas um bit é 1 e os demais são zero, conforme a tabela a seguir.\n",
        "\n",
        "| Decimal | Binary | One-hot\n",
        "| ------- | ------ | -------\n",
        "| 0 | 000    | 1 0 0 0 0 0 0 0\n",
        "| 1 | 001    | 0 1 0 0 0 0 0 0\n",
        "| 2 | 010    | 0 0 1 0 0 0 0 0\n",
        "| 3 | 011    | 0 0 0 1 0 0 0 0\n",
        "| 4 | 100    | 0 0 0 0 1 0 0 0\n",
        "| 5 | 101    | 0 0 0 0 0 1 0 0\n",
        "| 6 | 110    | 0 0 0 0 0 0 1 0\n",
        "| 7 | 111    | 0 0 0 0 0 0 0 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CqXP_5ABbfo"
      },
      "source": [
        "Implemente a função one_hot(y, n_classes) que codifique o vetor de inteiros y que possuem valores entre 0 e n_classes-1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la-02w7qCH7L"
      },
      "outputs": [],
      "source": [
        "def one_hot(y, n_classes):\n",
        "  one_hot_vector = np.zeros((len(y), n_classes))\n",
        "  one_hot_vector[[i for i in range(len(y))], y] = 1\n",
        "  return one_hot_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf5zyZO5Aiz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8c54f5-195d-48c6-f216-b3866373ac5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6 6 3 0 4 0 5 5 6 4]\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "N_CLASSES = 9\n",
        "N_SAMPLES = 10\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(int)\n",
        "print(y)\n",
        "print(one_hot(y, N_CLASSES))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwuKnQUCzve"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwuFy5rWC2tA"
      },
      "outputs": [],
      "source": [
        "N_SAMPLES = 100_000\n",
        "N_CLASSES = 1_000\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7azMtF7wDJ2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68e112b-b4db-4af0-e411-462561fc45ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193 ms ± 1.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "one_hot(y, N_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqMroZay2ubi"
      },
      "source": [
        "## Exercício 2.8\n",
        "\n",
        "Implemente uma classe que normalize um array de pontos flutuantes `array_a` para a mesma média e desvio padrão de um outro array `array_b`, conforme exemplo abaixo:\n",
        "```\n",
        "array_a = np.array([-1, 1.5, 0])\n",
        "array_b = np.array([1.4, 0.8, 0.3, 2.5])\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)  # Deve imprimir [0.3187798  2.31425165 1.11696854]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaedJ5Cf5Oy2"
      },
      "outputs": [],
      "source": [
        "# Escreva seu código aqui.\n",
        "import numpy as np\n",
        "\n",
        "class Normalizer:\n",
        "  def __init__(self, array):\n",
        "    self.mean = np.mean(array)\n",
        "    self.std  = np.std(array)\n",
        "\n",
        "  def __call__(self, array):\n",
        "    z_score = (array - np.mean(array)) / np.std(array)    \n",
        "    return z_score * self.std + self.mean "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkNNU6h5RbR"
      },
      "source": [
        "Mostre que seu código está correto com o exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gad6zsbh5a0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad18bbeb-2e31-4b65-b7ee-f7392b44496d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3187798  2.31425165 1.11696854]\n"
          ]
        }
      ],
      "source": [
        "array_a = [-1, 1.5, 0]\n",
        "array_b = [1.4, 0.8, 0.3, 2.5]\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrGVQFUYI_LP"
      },
      "source": [
        "# Parte 3:\n",
        "\n",
        "##Exercícios Pytorch: Grafo Computacional e Gradientes\n",
        "\n",
        "Nesta parte pode-se usar quaisquer bibliotecas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlQdKAuCZtR"
      },
      "source": [
        "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada através do cálculo automático do gradiente e construção dinâmica do grafo computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF_-dJ2nCZtT"
      },
      "source": [
        "## Grafo computacional\n",
        "\n",
        "Seja um exemplo simples de uma função de perda J dada pela Soma dos Erros ao Quadrado (SEQ - Sum of Squared Errors): \n",
        "$$ J = \\sum_i (x_i w - y_i)^2 $$\n",
        "que pode ser reescrita como:\n",
        "$$ \\hat{y_i} = x_i w $$\n",
        "$$ e_i = \\hat{y_i} - y_i $$\n",
        "$$ e2_i = e_i^2 $$\n",
        "$$ J = \\sum_i e2_i $$\n",
        "\n",
        "As redes neurais são treinadas através da minimização de uma função de perda usando o método do gradiente descendente. Para ajustar o parâmetro $w$ precisamos calcular o gradiente $  \\frac{ \\partial J}{\\partial w} $. Usando a\n",
        "regra da cadeia podemos escrever:\n",
        "$$ \\frac{ \\partial J}{\\partial w} = \\frac{ \\partial J}{\\partial e2_i} \\frac{ \\partial e2_i}{\\partial e_i} \\frac{ \\partial e_i}{\\partial \\hat{y_i} } \\frac{ \\partial \\hat{y_i}}{\\partial w}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jboejVQMCZtU"
      },
      "source": [
        "```\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7JmU6qhc2Y2"
      },
      "source": [
        "As quatro expressões acima, para o cálculo do J podem ser representadas pelo grafo computacional visualizado a seguir: os círculos são as variáveis (tensores), os quadrados são as operações, os números em preto são os cálculos durante a execução das quatro expressões para calcular o J (forward, predict). O cálculo do gradiente, mostrado em vermelho, é calculado pela regra da cadeia, de trás para frente (backward)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeeEBKl4CZtV"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/robertoalotufo/files/master/figures/GrafoComputacional.png\" width=\"600pt\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZun7wrCZtX"
      },
      "source": [
        "Para entender melhor o funcionamento do grafo computacional com os tensores, recomenda-se leitura em:\n",
        "\n",
        "https://pytorch.org/docs/stable/notes/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlT2d-4fCZtZ"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xX0QwUduCZtf",
        "outputId": "bf9b5d41-c7d4-4861-aed4-6ffa8a7ea5b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.1+cu113'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqzALS4CZtl"
      },
      "source": [
        "**Tensor com atributo .requires_grad=True**\n",
        "\n",
        "Quando um tensor possui o atributo `requires_grad` como verdadeiro, qualquer expressão que utilizar esse tensor irá construir um grafo computacional para permitir posteriormente, após calcular a função a ser derivada, poder usar a regra da cadeia e calcular o gradiente da função em termos dos tensores que possuem o atributo `requires_grad`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foaAb94aCZtm",
        "outputId": "d61e8beb-87db-4e8f-9c3e-c1b98910acd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "y = torch.arange(0, 8, 2).float()\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no6SdSyICZtr",
        "outputId": "7b4d91bc-f472-414c-aad0-091c389c35ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "x = torch.arange(0, 4).float()\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL_i1mwGCZtw",
        "outputId": "cc3f69b9-3dbf-4673-9217-849bb9c54ec1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "w = torch.ones(1, requires_grad=True)\n",
        "w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjEl-0l7CZt0"
      },
      "source": [
        "## Cálculo automático do gradiente da função perda J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pUh-SCnCZt1"
      },
      "source": [
        "Seja a expressão: $$ J = \\sum_i ((x_i  w) - y_i)^2 $$\n",
        "\n",
        "Queremos calcular a derivada de $J$ em relação a $w$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwwVtJ1CZt2"
      },
      "source": [
        "## Forward pass\n",
        "\n",
        "Durante a execução da expressão, o grafo computacional é criado. Compare os valores de cada parcela calculada com os valores em preto da figura ilustrativa do grafo computacional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp2aK4YhCZt3",
        "outputId": "e2e25c84-6f4c-4c2d-98a4-68134e77df1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred = tensor([0., 1., 2., 3.], grad_fn=<MulBackward0>)\n",
            "e = tensor([ 0., -1., -2., -3.], grad_fn=<SubBackward0>)\n",
            "e2 = tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)\n",
            "J = tensor(14., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# predict (forward)\n",
        "y_pred = x * w; print('y_pred =', y_pred)\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "e = y_pred - y; print('e =',e)\n",
        "e2 = e.pow(2) ; print('e2 =', e2)\n",
        "J = e2.sum()  ; print('J =', J)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC96wB7PCZt8"
      },
      "source": [
        "## Backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKbf4D0CCZt-"
      },
      "source": [
        "O `backward()` varre o grafo computacional a partir da variável a ele associada (raiz) e calcula o gradiente para todos os tensores que possuem o atributo `requires_grad` como verdadeiro.\n",
        "Observe que os tensores que tiverem o atributo `requires_grad` serão sempre folhas no grafo computacional.\n",
        "O `backward()` destroi o grafo após sua execução. Esse comportamento é padrão no PyTorch. \n",
        "\n",
        "A título ilustrativo, se quisermos depurar os gradientes dos nós que não são folhas no grafo computacional, precisamos primeiro invocar `retain_grad()` em cada um desses nós, como a seguir. Entretanto nos exemplos reais não há necessidade de verificar o gradiente desses nós."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-CjLPu6clVo"
      },
      "outputs": [],
      "source": [
        "e2.retain_grad()\n",
        "e.retain_grad()\n",
        "y_pred.retain_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtsZS2Bicof-"
      },
      "source": [
        "E agora calculamos os gradientes com o `backward()`.\n",
        "\n",
        "w.grad é o gradiente de J em relação a w."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1lnkb0GCZt_",
        "outputId": "30f322a5-0194-4908-89dc-6d0cdd357264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-28.])\n"
          ]
        }
      ],
      "source": [
        "if w.grad: w.grad.zero_()\n",
        "J.backward()\n",
        "print(w.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1xYDPR_uOcZ"
      },
      "source": [
        "Mostramos agora os gradientes que estão grafados em vermelho no grafo computacional:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enuk2tf0sDyO",
        "outputId": "0d867593-792d-4521-cd5c-9872af5c9f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.])\n",
            "tensor([ 0., -2., -4., -6.])\n",
            "tensor([ 0., -2., -4., -6.])\n"
          ]
        }
      ],
      "source": [
        "print(e2.grad)\n",
        "print(e.grad)\n",
        "print(y_pred.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsOThnt8fDJV"
      },
      "source": [
        "##Exercício 3.1\n",
        "Calcule o mesmo gradiente ilustrado no exemplo anterior usando a regra das diferenças finitas, de acordo com a equação a seguir, utilizando um valor de $\\Delta w$ bem pequeno.\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62nZAfUoCZu5",
        "outputId": "ab7ef443-f017-4141-bb80-9623df6b33da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grad= tensor(-28.0000)\n"
          ]
        }
      ],
      "source": [
        "def J_func(w, x, y):\n",
        "    # programe a função J_func, para facilitar\n",
        "    return sum((x*w - y)**2)\n",
        "\n",
        "# Calcule o gradiente usando a regra diferenças finitas\n",
        "# Confira com o valor já calculado anteriormente\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "delta_w = 1e-2\n",
        "grad = (J_func(w+delta_w, x, y) - J_func(w-delta_w, x, y)) / (2*delta_w)\n",
        "print('grad=', grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Sx1QXZxJ3u"
      },
      "source": [
        "##Exercício 3.2\n",
        "\n",
        "Minimizando $J$ pelo gradiente descendente\n",
        "\n",
        "$$ w_{k+1} = w_k - \\lambda \\frac {\\partial J}{\\partial w} $$\n",
        "\n",
        "Supondo que valor inicial ($k=0$) $w_0 = 1$, use learning rate $\\lambda = 0.01$ para calcular o valor do novo $w_{20}$, ou seja, fazendo 20 atualizações de gradientes. Deve-se usar a função `J_func` criada no exercício anterior.\n",
        "\n",
        "Confira se o valor do primeiro gradiente está de acordo com os valores já calculado acima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNszCOED1Wtu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67997b9b-e66a-4e48-9c0e-cd116a9bee8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14.)\n",
            "grad = tensor(-28.0000)\n",
            "w = tensor([1.2800])\n",
            "i = 1\n",
            "J= tensor(7.2576)\n",
            "grad = tensor(-20.1600)\n",
            "w = tensor([1.4816])\n",
            "i = 2\n",
            "J= tensor(3.7623)\n",
            "grad = tensor(-14.5151)\n",
            "w = tensor([1.6268])\n",
            "i = 3\n",
            "J= tensor(1.9504)\n",
            "grad = tensor(-10.4509)\n",
            "w = tensor([1.7313])\n",
            "i = 4\n",
            "J= tensor(1.0111)\n",
            "grad = tensor(-7.5247)\n",
            "w = tensor([1.8065])\n",
            "i = 5\n",
            "J= tensor(0.5242)\n",
            "grad = tensor(-5.4178)\n",
            "w = tensor([1.8607])\n",
            "i = 6\n",
            "J= tensor(0.2717)\n",
            "grad = tensor(-3.9008)\n",
            "w = tensor([1.8997])\n",
            "i = 7\n",
            "J= tensor(0.1409)\n",
            "grad = tensor(-2.8086)\n",
            "w = tensor([1.9278])\n",
            "i = 8\n",
            "J= tensor(0.0730)\n",
            "grad = tensor(-2.0222)\n",
            "w = tensor([1.9480])\n",
            "i = 9\n",
            "J= tensor(0.0379)\n",
            "grad = tensor(-1.4560)\n",
            "w = tensor([1.9626])\n",
            "i = 10\n",
            "J= tensor(0.0196)\n",
            "grad = tensor(-1.0483)\n",
            "w = tensor([1.9730])\n",
            "i = 11\n",
            "J= tensor(0.0102)\n",
            "grad = tensor(-0.7548)\n",
            "w = tensor([1.9806])\n",
            "i = 12\n",
            "J= tensor(0.0053)\n",
            "grad = tensor(-0.5434)\n",
            "w = tensor([1.9860])\n",
            "i = 13\n",
            "J= tensor(0.0027)\n",
            "grad = tensor(-0.3913)\n",
            "w = tensor([1.9899])\n",
            "i = 14\n",
            "J= tensor(0.0014)\n",
            "grad = tensor(-0.2817)\n",
            "w = tensor([1.9928])\n",
            "i = 15\n",
            "J= tensor(0.0007)\n",
            "grad = tensor(-0.2028)\n",
            "w = tensor([1.9948])\n",
            "i = 16\n",
            "J= tensor(0.0004)\n",
            "grad = tensor(-0.1460)\n",
            "w = tensor([1.9962])\n",
            "i = 17\n",
            "J= tensor(0.0002)\n",
            "grad = tensor(-0.1052)\n",
            "w = tensor([1.9973])\n",
            "i = 18\n",
            "J= tensor(0.0001)\n",
            "grad = tensor(-0.0757)\n",
            "w = tensor([1.9981])\n",
            "i = 19\n",
            "J= tensor(5.3059e-05)\n",
            "grad = tensor(-0.0545)\n",
            "w = tensor([1.9986])\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "\n",
        "history_J = []\n",
        "history_i = []\n",
        "\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    print('J=', J)\n",
        "    grad = (J_func(w + delta_w, x, y) - J_func(w - delta_w, x, y)) / (2 * delta_w)\n",
        "    print('grad =',grad)\n",
        "    w = w - learning_rate * grad\n",
        "    print('w =', w)\n",
        "\n",
        "    history_J.append(J)\n",
        "    history_i.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plote o gráfico da loss J pela iteração i\n",
        "plt.plot(history_i, history_J)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('J')\n",
        "plt.title('Loss Function for each iteration')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Z-qGCf1W8tLJ",
        "outputId": "ed70ad79-0937-445a-ca21-2a6dedd019fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhc9X3v8fd3NLIkW7JlWbK8WwZLNsZsrsIaCGAKNiVA+vRJSUgaElqa3pClTW4KIdttk9yUpElolqa+gZCkhNASSLi5OEBCgLAEMA6LF7xgvNuSbGNZXiRr+d4/zpEZixlJtjRzNHM+r+eZZ8425/edo6PvOed3fvM75u6IiEh8JKIOQEREckuJX0QkZpT4RURiRolfRCRmlPhFRGJGiV9EJGaU+KUgmNl+MzshC+udY2YvmlmbmX1suNc/HMyszszczJKDXP77Zva5bMc1QAwrzezCKGOIMyX+AmJmG83skgjKvdPMDofJt/f1l1ks7zEz++vUae5e7u4bslDcp4HfuXuFu/9bFtafc+7+YXf/ZwAzu9DMtmazvHD/+FKfGE5298eyWa5kpsQvw+XWMPn2vu6JOqBhMhNYeTwfHOwZeD6Lw3csREr8MWBmJWb2LTPbHr6+ZWYl4bxqM/uVme01sz1m9nszS4Tz/tHMtoXVHGvMbOExlnvUmV7fs8vwCuVTZvaymbWa2T1mVpoy/6qwmmWfmb1mZovM7MvA+cB3wiuL74TLupnNDofHmdmPzazFzDaZ2WdTvtN1ZvakmX3dzN4ws9fNbHGG+B8FLkopq2EQ637KzL5pZruBL6ZZZ8LMbgq/z24z+y8zq0qZ/99mtjPcHk+Y2ckp88rM7F/DclvD71GWsvprzWyzme0ys1sG+ruY2RhgKTAl5UptSn8xplQrXW9mm4FH+4vbzG4ArgU+Ha7//6b87S8Jh/vbPy80s61m9kkzazazHWb2wUzfTQZHiT8ebgHOBk4HTgPOBD4bzvsksBWoAWqBzwBuZnOAG4G3uXsFcBmwMQuxvRtYBMwCTgWuAzCzM4EfA/8TqAQuADa6+y3A74EbwyuLG9Os89vAOOAE4B3AXwGpyeIsYA1QDdwK3G5m1ncl7n5xn7LWDnLdGwi25ZfTxPZR4Orws1OAN4DvpsxfCtQDE4HlwF0p874O/AlwLlBFUA3VkzL/7cAcYCHweTM7KU35qd/vALAY2J5ypbZ9EDESzjuJYL/IGLe7LwmHe68I35kmlP72T4BJBNt8KnA98F0zG9/fd5MBuLteBfIiSMyXpJn+GnB5yvhlBEkU4J+AXwKz+3xmNtAMXAIUD1DunUA7sDd87UqZ/qWU5S4EtvaJ930p47cC3w+H/wP4ZobyHgP+us80D2MuAg4D81Lm/S3wWDh8HbA+Zd7o8LOTBiprkOvePMC2Wg0sTBmfDHQCyTTLVoaxjSM4STsEnJZmubpwuWkp054Drunn7/WldH+TgWJMKeuEfr7jkbjT7Qd991X63z8vDL93MmV+M3B21P9v+fzSGX88TAE2pYxvCqcBfA1YDzxsZhvM7CYAd18PfIKguqLZzH5mZlPI7OvuXhm+qo8htp0pwweB8nB4OkFCOFbVQDFv/b5T05Xp7gfDwXIGNph1bxlgHTOB+8Oqtb0ESbYbqDWzIjP7aljFso83r7Cqw1cp/W+TTNvyWGWMMWWZI99zgLgHo7/9E2C3u3eljA/luwmq6omL7QT/zL1mhNNw9zZ3/6S7nwBcCfyDhXX57v5Td397+FkH/uUYyz1AcEbda9IxfHYLcGKGef11KbuL4Oy07/fddgxlD2XdA3V3uwVYnHKQrHT3UnffBrwXuIrgKmscwdk1gIVlt5N5mxyvdPH2F2O6z/UXd6YyUmXcPyU7lPgLT7GZlaa8ksDdwGfNrMbMqoHPA/8JYGZXmNnssI67leDMrseC9usXhzfZ2gkut3vSF5nRi8DlZlZlZpMIriAG63bgg2a2MLzZONXM5obzmgjq2N/C3buB/wK+bGYVZjYT+Ife7zsUw7Tu74efnwkQ/k2uCudVAB3AboID5ldSyu4B7gC+Ed6ALTKzc3pvgg5BEzDBzMYNMsZ0MsadUkZ/v7HIuH9KdijxF54HCZJ07+uLwJeAZcDLwCsEN996W9vUA78B9gPPAN9z998BJcBXCc40dxLctLv5GGP5CfASwaX/w8Cgm3i6+3MEN02/SXBAepw3zwpvA/7CglY56drWf5TgamMD8CTwU4KkORyGuu7bgAcIqtbagD8Q3BCG4Gb2JoIriFXhvFSfIvj7PQ/sIbgCG9L/sLu/SpB4N4RVO1MGiDGdgeK+HZgXrv8XaT7f3/4pWWDhzRIREYkJnfGLiMSMEr+ISMwo8YuIxIwSv4hIzORFB0vV1dVeV1cXdRgiInnlhRde2OXuNX2n50Xir6urY9myZVGHISKSV8xsU7rpquoREYkZJX4RkZhR4hcRiRklfhGRmFHiFxGJmawlfjO7I3xU2oo08z4ZPr7tWPptFxGRYZDNM/47CR6pdxQzmw5cCmzOYtkiIpJB1hK/uz9B0HVsX98keFZo1rsFffTVJr732PpsFyMikldyWscfPsxhm7u/NIhlbzCzZWa2rKWl5bjKe3r9bm77zTq6e9T1tIhIr5wlfjMbDXyG4Ok6A3L3Je7e6O6NNTVv+cXxoDTUVtDR1cOWPQcHXlhEJCZyecZ/IjALeMnMNgLTgOXhI/myor42eB7z2qa2bBUhIpJ3cpb43f0Vd5/o7nXuXgdsBRa4+85slVlfWwHAuub92SpCRCTvZLM5590Ez3CdY2Zbzez6bJWVSXlJkqmVZazZqTN+EZFeWeud093fM8D8umyVnaq+tlxVPSIiKQr+l7sNtRVsaDlAV3dP1KGIiIwIBZ/46yeWc7i7h01q2SMiAsQg8Tf03uBVdY+ICBCDxD97Ym+TTrXsERGBGCT+MSVJpo0v0w1eEZFQwSd+CKp71umMX0QEiFHi37BrP51q2SMiEpfEX05nt7Np94GoQxERiVxMEn/Qskc3eEVEYpL4T6wpx0ydtYmIQEwSf9moImZUjdYNXhERYpL4AeonVuiMX0SEGCX+htpyXt91gMNdatkjIvEWo8RfQVeP8/outewRkXiLTeLX07hERAKxSfwn1pSTMHXWJiISm8RfWlzEzAlj1JZfRGIvNokfgr751zbrjF9E4i1Wib+htoJNuw/S0dUddSgiIpHJ5sPW7zCzZjNbkTLta2b2qpm9bGb3m1lltspPp2FSBd09zoYWtewRkfjK5hn/ncCiPtMeAea7+6nAWuDmLJb/Fg1q2SMikr3E7+5PAHv6THvY3bvC0T8A07JVfjqzqsdQlDB13SAisRZlHf+HgKWZZprZDWa2zMyWtbS0DEuBJcki6iaM1hm/iMRaJInfzG4BuoC7Mi3j7kvcvdHdG2tqaoat7IbaCtY164xfROIr54nfzK4DrgCudXfPdfn1tRVs2n2A9k617BGReMpp4jezRcCngSvd/WAuy+7VUFtOj8NrLTrrF5F4ymZzzruBZ4A5ZrbVzK4HvgNUAI+Y2Ytm9v1slZ/Jm0/jUj2/iMRTMlsrdvf3pJl8e7bKG6y6CWNIJkxdN4hIbMXql7sAo5IJZlWPUWdtIhJbsUv8EFT36IxfROIqlom/vracLW8c5NBhtewRkfiJZeKfU1uBO6xXe34RiaFYJv56tewRkRiLZeKvmzCaUUUJ9c0vIrEUy8SfLEpwQs0YddYmIrEUy8QPQXWPqnpEJI5im/gbJpaz9Y1DHOjoGnhhEZECEtvE33uDVy17RCRuYpv49TQuEYmr2Cb+mRPGMCqZUN/8IhI7sU38RQnjxJpy1uzUGb+IxEtsEz8E1T3qrE1E4ibmib+C7a3ttLV3Rh2KiEjOxDrx108MbvCqnl9E4iTWiX/OpKBJp6p7RCROYp34p48fTWlxQn3zi0isxDrxJxLG7InlassvIrES68QP0DCxQp21iUisZC3xm9kdZtZsZitSplWZ2SNmti58H5+t8gervraCnfvaaT2klj0iEg/ZPOO/E1jUZ9pNwG/dvR74bTgeqd6uG9arb34RiYmsJX53fwLY02fyVcCPwuEfAVdnq/zBajjyNC5V94hIPOS6jr/W3XeEwzuB2kwLmtkNZrbMzJa1tLRkLaCplWWUFRfpBq+IxEZkN3fd3QHvZ/4Sd29098aampqsxZFIGPW15brBKyKxkevE32RmkwHC9+Ycl59W/UQ9jUtE4iPXif8B4APh8AeAX+a4/LQaastpbutg78HDUYciIpJ12WzOeTfwDDDHzLaa2fXAV4E/NbN1wCXheOR0g1dE4iSZrRW7+3syzFqYrTKPV8Ok3sTfxpmzqiKORkQku2L/y12AKeNKKS9JqrM2EYkFJX7ArLfPHlX1iEjhU+IPNdSWs06/3hWRGFDiDzXUVrBr/2H2HFDLHhEpbEr8ofraN2/wiogUMiX+UG9nbbrBKyKFTok/NGlsKRUlSd3gFZGCp8QfMgv67FFVj4gUOiX+FA21Faxr1hm/iBQ2Jf4U9bUV7DlwmF37O6IORUQka5T4U/Te4FV1j4gUMiX+FEc6a9upxC8ihUuJP8XEihLGlRWzVvX8IlLAlPhTmFnQdYOqekSkgCnx91FfW8Hapv0ET4YUESk8Svx9NEwsp/VQJy1tatkjIoVJib8PPY1LRAqdEn8f6qxNRAqdEn8f1eWjGD+6WH3zi0jBiiTxm9nfm9lKM1thZnebWWkUcaQT9NlToaoeESlYOU/8ZjYV+BjQ6O7zgSLgmlzH0Z+GsLM2tewRkUIUVVVPEigzsyQwGtgeURxpNdRW0NbeRdM+tewRkcKT88Tv7tuArwObgR1Aq7s/3Hc5M7vBzJaZ2bKWlpacxlg/UTd4RaRwRVHVMx64CpgFTAHGmNn7+i7n7kvcvdHdG2tqanIaozprE5FCFkVVzyXA6+7e4u6dwH3AuRHEkdGE8hKqy0exTjd4RaQARZH4NwNnm9loMzNgIbA6gjj6VT+xgjU64xeRAhRFHf+zwL3AcuCVMIYluY5jIA215axvVp89IlJ4klEU6u5fAL4QRdmDVV9bwf6OLra3tjO1sizqcEREho1+uZtBg7puEJECpcSfQW/LHvXNLyKFRok/g8rRo6ipKFHXDSJScJT4+6GncYlIIVLi78fcSWN5dWcbhw53Rx2KiMiwUeLvx8VzJ9LR1cPja5ujDkVEZNgo8ffjrFlVjB9dzNIVO6MORURk2Cjx9yNZlOBP59Xy6OpmOrpU3SMihSFj4jezNjPbl+HVYmZ/MLOFuQw2CovnT6ato4un1u+KOhQRkWGR8Ze77l6RaZ6ZFQHzgbvC94J17uwJVJQkWfrKTi6eWxt1OCIiQ3ZcVT3u3u3uLwHfHuZ4RpySZBELT5rII6ub6OzuiTocEZEhG1Idv7v/x3AFMpItmj+ZvQc7eXbDnqhDEREZMt3cHYR3NNRQVlzE0hU7og5FRGTIlPgHoWxUERfNreGhlU1096ibZhHJb0r8g7Ro/mR27e/ghU1vRB2KiMiQKPEP0sVzJzIqmVB1j4jkPSX+QSovSXJBfQ2/XrGTHlX3iEgeU+I/BovnT2JHazsvbd0bdSgiIsdNif8YXHJSLcmE8Wv13SMieSySxG9mlWZ2r5m9amarzeycKOI4VuNGF3Pu7GqWrtiph7CLSN6K6oz/NuDX7j4XOA1YHVEcx2zx/Els3nOQVTv2RR2KiMhxyXniN7NxwAXA7QDuftjd86bS/NJ5tSQMVfeISN6K4ox/FtAC/NDM/mhmPzCzMX0XMrMbzGyZmS1raWnJfZQZTCgv4cxZVeqjX0TyVhSJPwksAP7d3c8ADgA39V3I3Ze4e6O7N9bU1OQ6xn4tnj+Z9c37Wd+s5/GKSP6JIvFvBba6+7Ph+L0EB4K8cdnJkwBY+orO+kUk/+Q88bv7TmCLmc0JJy0EVuU6jqGYNK6UBTMqVd0jInkpqlY9HwXuMrOXgdOBr0QUx3G7/JTJrNqxj027D0QdiojIMYkk8bv7i2H9/anufrW7513PZ0eqe3TWLyJ5Rr/cPU7Tq0ZzytRxSvwikneU+Idg0fxJvLRlL9v3Hoo6FBGRQVPiH4LF84PqHv2YS0TyiRL/EJxQU86c2golfhHJK0r8Q7Ro/iSe37SH5rb2qEMRERkUJf4hWnzKJNzh4ZVNUYciIjIoSvxDNKe2glnVY1TdIyJ5Q4l/iMyMRfMn8cyG3bxx4HDU4YiIDEiJfxhcPn8y3T3OI6tV3SMiI58S/zCYP3Us08aXqbpHRPKCEv8wMDMWnTyJ369rYV97Z9ThiIj0S4l/mCw+ZRKd3c6jq5ujDkVEpF9K/MPkjOnjqR1bwtIVO6IORUSkX0r8wySRMC47eRKPr23h4OGuqMMREclIiX8YLZo/ifbOHh5bM3KeESwi0pcS/zA6s66KqjGj1FWziIxoSvzDKFmU4NJ5tTy6uon2zu6owxERSUuJf5gtmj+JA4e7eXLdrqhDERFJS4l/mJ17YjVjS5Oq7hGRESuyxG9mRWb2RzP7VVQxZMOoZIJL5tXym9VNdHb3RB2OiMhbRHnG/3FgdYTlZ83i+ZNpPdTJM6/tjjoUEZG3iCTxm9k04M+AH0RRfradX1/NmFFF+jGXiIxIUZ3xfwv4NJCxLsTMbjCzZWa2rKUlv9rFlxYXcdHciTy8sonuHo86HBGRo+Q88ZvZFUCzu7/Q33LuvsTdG929saamJkfRDZ/F8yez+8Bhnnt9T9ShiIgcJYoz/vOAK81sI/Az4GIz+88I4siqC+fUUJJM8GtV94jICJPzxO/uN7v7NHevA64BHnX39+U6jmwbU5LkHQ01PLhiJ4cO68dcIjJyqB1/Fl3/9lm0tHVw22/XRR2KiMgRkSZ+d3/M3a+IMoZsOuuECby7cRo/+P0GXt25L+pwREQAnfFn3c2LT2JsWTE33/cKPWrhIyIjgBJ/lo0fM4rPXXESf9y8l7ue2xx1OCIiSvy5cPXpUzlv9gRuXfoqzfvaow5HRGJOiT8HzIwvXX0KHd09/K9frYo6HBGJOSX+HJlVPYaPXTyb//fyDn73qh7ILiLRUeLPoRsuOJHZE8v57C9W6Lm8IhIZJf4cGpVM8JV3ncK2vYe47Tdq2y8i0VDiz7EzZ1Vxzdum84MnX2fVdrXtF5HcU+KPwE2L5zJ+dDE33/+Keu8UkZxT4o9A5ehRfO6Keby0ZS93Pbsp6nBEJGaU+CNy5WlTOL++mlt/vYYmte0XkRxS4o9I0LZ/Pp3dPXzxgZVRhyMiMaLEH6GZE8bwsYX1LF2xk9+saoo6HBGJCSX+iP3N+SfQUFvOFx5YyYEOte0XkexT4o9Yatv+bz6yNupwRCQGlPhHgMa6Kt571gzueOp1VmxrjTocESlwSvwjxD9eNpeqMSV8Rm37RSTLlPhHiHGji/n8O+fx8tZWfvLMxqjDEZECpsQ/grzz1Mlc0FDD1x5aw47WQ1GHIyIFSol/BDEzvnz1fLrd1bZfRLIm54nfzKab2e/MbJWZrTSzj+c6hpFsetVoPr6wgYdWNvHwyp1RhyMiBSiKM/4u4JPuPg84G/iImc2LII4R66/Pn8XcSRV84YGV7FfbfhEZZjlP/O6+w92Xh8NtwGpgaq7jGMmKixJ8+V2nsHNfO19/aE3U4YhIgYm0jt/M6oAzgGfTzLvBzJaZ2bKWlpZchxa5P5k5nvefPZM7n97I/35wtZp4isiwSUZVsJmVAz8HPuHub3kiibsvAZYANDY2xjLrfe6KebjDfzyxgXXN+7ntmtOpKC2OOiwRyXORnPGbWTFB0r/L3e+LIoZ8UFyU4J+vns8/X3Uyj69t4c+/9zSbdx+MOiwRyXNRtOox4HZgtbt/I9fl56P3n1PHTz50Js1tHVz53Sd55rXdUYckInksijP+84D3Axeb2Yvh6/II4sgr586u5pcfOY8JY0bx/tuf5afPbo46JBHJUzmv43f3JwHLdbmFoK56DPd/5Dw+dvcf+cz9r7C2qY3P/tlJJIv0OzwRGTxljDwztrSY2z/wNv7m/Fnc+fRGrvvh87Qe7Iw6LBHJI0r8eagoYdzyZ/O49S9O5dnXd3P1957itZb9UYclInlCiT+PvbtxOj/9m7PZd6iTq7/7FI+vjd/vHUTk2Cnx57m31VXxyxvPY2plGR/84XPc8eTruMfyZw8iMkhK/AVg2vjR/PzvzuWSk2r5p1+t4ub7XuFwV0/UYYnICKXEXyDGlCT5/vv+hBsvms3Pnt/C+25/lj0HDkcdloiMQEr8BSSRMD512Rxuu+Z0Xtqylyu/8ySv7nxLbxgiEnNK/AXoqtOn8l9/ew6Hu3p457ef5O/veZGXtuyNOiwRGSEsH24ENjY2+rJly6IOI+8072vne4+9xr0vbGV/RxdnzKjkunPrWDx/MqOSOuaLFDoze8HdG98yXYm/8LW1d/LzF7byo2c28fquA0ysKOHas2by3rNmUFNREnV4IpIlSvxCT4/z+LoW7nxqI4+vbWFUUYIrTp3MdefVceq0yqjDE5FhlinxR9Yfv+ReImFcNGciF82ZyGst+/nJM5v472VbuO+P21gwo5LrzpvF4vmTKFbfPyIFTWf8MdfW3sm9L2zlR09vZOPug9SODaqB3nOmqoFE8p2qeqRfPT3O42tb+OHTG3mitxrotMlce9YMTp1WqasAkTykqh7pVyJhXDR3IhfNncj65v38+JmN/PyFrdy3fBulxQlOnVrJGTMrWTBjPAtmjNfVgEge0xm/ZLSvvZPH17SwfPMbLN+8l1XbW+nsDvaX6VVlRw4CC2aMZ+7kCl0ViIwwquqRIWvv7Gbl9laWb9obHgzeoGlfB0BwVTCt94qgkgUzx1NdrqsCkSgp8cuwc3e2t7azfNMbaa8KZlSN5pRp45g2vowp48qYUlnG5HGlTK0so3J0McHjl0UkW1THL8POzJhaWcbUyjLeedoUILgqWLGtNTgQbNrLim2tPLKyicPdR/cWWlqcYEpl7wGhlMnjgvVMriw9Mr1sVFEUX0uk4EWS+M1sEXAbUAT8wN2/GkUcMvxKi4torKuisa7qyLSeHmf3gcPsaD3E9r2H2La3nR17D7G99RDb97bz2JoWWvZ30Pfic/zoYmrHljK2rJixpUkqSoupKE0yNnyvKC1mbNnR03uXKy1O6IpCJIOcJ34zKwK+C/wpsBV43swecPdVuY5FciORMGoqSqipKMn4C+HDXT007Wtne8oBYfveQzTt66CtvZNte9tpa2+jrb2LtvZOegaooSwuMipKiykvSVJanGBUMkFJsoiSZCJ8FVFSnDKcTITjKcsUFzGqKEGyyChKGMmEkUwkKCoKhot6xxMp40XBtN7x3pcZJMzCV3C1VJQIhhOWfr5ItkRxxn8msN7dNwCY2c+AqwAl/hgblUwwvWo006tGD7isu3PgcDdt7Z20tXex71D43t7JvvDA0Dt9f0cXh7t66OjqoaOrm47OHtrau4Lhrh46Ons43N1DR2cw3jXQESWHihKGAWZgBAeHo4YJDhAGkHIASZ1uvTOPrIcjw8Ec6zP+1oNO6uhRw/Sz3FHT+z+IDXiIG+IxcKiH0KgPwl951ymcOatq4AWPQRSJfyqwJWV8K3BW34XM7AbgBoAZM2bkJjLJC2ZGeUmS8pIkk8cN77q7unsPBG8eLLp7nK4ep6vbw+GeI9PefO+hs/vo8d7lexx63HF/c7i7x/FwON38ntTPAe7gBJ9xD9/7TIfe9aQsG36vYL6nDKe8p0w/evk35/Hmx/sOhst72nkDtR0Z6DA71MYnQz6Mj4DzgDElw3+va8Te3HX3JcASCFr1RByOxESyKEGyKMHoUVFHIpI9UfziZhswPWV8WjhNRERyIIrE/zxQb2azzGwUcA3wQARxiIjEUs6rety9y8xuBB4iaM55h7uvzHUcIiJxFUkdv7s/CDwYRdkiInGnXrVERGJGiV9EJGaU+EVEYkaJX0QkZvKiW2YzawE2HefHq4FdwxjOcFN8Q6P4hkbxDd1IjnGmu9f0nZgXiX8ozGxZuv6oRwrFNzSKb2gU39DlQ4x9qapHRCRmlPhFRGImDol/SdQBDEDxDY3iGxrFN3T5EONRCr6OX0REjhaHM34REUmhxC8iEjMFk/jNbJGZrTGz9WZ2U5r5JWZ2Tzj/WTOry2Fs083sd2a2ysxWmtnH0yxzoZm1mtmL4evzuYovLH+jmb0Slr0szXwzs38Lt9/LZrYgh7HNSdkuL5rZPjP7RJ9lcrr9zOwOM2s2sxUp06rM7BEzWxe+j8/w2Q+Ey6wzsw/kML6vmdmr4d/vfjNL+wDkgfaFLMb3RTPblvI3vDzDZ/v9X89ifPekxLbRzF7M8Nmsb78h8/CRb/n8Iuje+TXgBGAU8BIwr88y/wP4fjh8DXBPDuObDCwIhyuAtWniuxD4VYTbcCNQ3c/8y4GlBI8wPRt4NsK/9U6CH6ZEtv2AC4AFwIqUabcCN4XDNwH/kuZzVcCG8H18ODw+R/FdCiTD4X9JF99g9oUsxvdF4FOD+Pv3+7+erfj6zP9X4PNRbb+hvgrljP/IA9zd/TDQ+wD3VFcBPwqH7wUWWo6eouzuO9x9eTjcBqwmePZwPrkK+LEH/gBUmtnkCOJYCLzm7sf7S+5h4e5PAHv6TE7dx34EXJ3mo5cBj7j7Hnd/A3gEWJSL+Nz9YXfvCkf/QPD0u0hk2H6DMZj/9SHrL74wb7wbuHu4y82VQkn86R7g3jexHlkm3PlbgQk5iS5FWMV0BvBsmtnnmNlLZrbUzE7OaWDBY6UfNrMXwgfd9zWYbZwL15D5Hy7K7QdQ6+47wuGdQG2aZUbKdvwQwRVcOgPtC9l0Y1gVdUeGqrKRsP3OB5rcfV2G+VFuv0EplMSfF8ysHPg58Al339dn9nKC6ovTgG8Dv8hxeG939wXAYuAjZnZBjssfUPioziuB/04zO+rtdxQPrvlHZFtpM7sF6ALuyrBIVPvCvwMnAqcDOwiqU0ai99D/2f6I/18qlMQ/mAe4H1nGzJLAOGB3TqILyiwmSPp3uft9fee7+z533x8OPwgUmxaKZi0AAAOsSURBVFl1ruJz923hezNwP8EldarBbONsWwwsd/emvjOi3n6hpt7qr/C9Oc0ykW5HM7sOuAK4Njw4vcUg9oWscPcmd+929x7g/2QoN+rtlwT+HLgn0zJRbb9jUSiJfzAPcH8A6G1B8RfAo5l2/OEW1gneDqx2929kWGZS7z0HMzuT4G+TkwOTmY0xs4reYYKbgCv6LPYA8Fdh656zgdaUao1cyXimFeX2S5G6j30A+GWaZR4CLjWz8WFVxqXhtKwzs0XAp4Er3f1ghmUGsy9kK77Ue0bvylDuYP7Xs+kS4FV335puZpTb75hEfXd5uF4ErU7WEtzxvyWc9k8EOzlAKUEVwXrgOeCEHMb2doLL/peBF8PX5cCHgQ+Hy9wIrCRopfAH4NwcxndCWO5LYQy92y81PgO+G27fV4DGHP99xxAk8nEp0yLbfgQHoB1AJ0E98/UE94x+C6wDfgNUhcs2Aj9I+eyHwv1wPfDBHMa3nqB+vHcf7G3lNgV4sL99IUfx/STct14mSOaT+8YXjr/lfz0X8YXT7+zd51KWzfn2G+pLXTaIiMRMoVT1iIjIICnxi4jEjBK/iEjMKPGLiMSMEr+ISMwo8UusmNn+8L3OzN47zOv+TJ/xp4dz/SLDRYlf4qoOOKbEH/5qsz9HJX53P/cYYxLJCSV+iauvAueHfab/vZkVhf3VPx92Eva3cKSf/9+b2QPAqnDaL8IOuFb2dsJlZl8FysL13RVO6726sHDdK8J+2v8yZd2Pmdm9FvSTf1eueoyVeBvoDEakUN1E0Pf7FQBhAm9197eZWQnwlJk9HC67AJjv7q+H4x9y9z1mVgY8b2Y/d/ebzOxGdz89TVl/TtDx2GlAdfiZJ8J5ZwAnA9uBp4DzgCeH/+uKvEln/CKBSwn6InqRoMvsCUB9OO+5lKQP8DEz6+0aYnrKcpm8Hbjbgw7ImoDHgbelrHurBx2TvUhQBSWSVTrjFwkY8FF3P6rDNDO7EDjQZ/wS4Bx3P2hmjxH0A3W8OlKGu9H/pOSAzvglrtoIHoPZ6yHg78LuszGzhrB3xb7GAW+ESX8uwWMoe3X2fr6P3wN/Gd5HqCF4rN9zw/ItRI6Dzi4krl4GusMqmzuB2wiqWZaHN1hbSP/oxF8DHzaz1cAaguqeXkuAl81subtfmzL9fuAcgh4bHfi0u+8MDxwiOafeOUVEYkZVPSIiMaPELyISM0r8IiIxo8QvIhIzSvwiIjGjxC8iEjNK/CIiMfP/AWtCbN2H+XIyAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBXxBmWGK3IU"
      },
      "source": [
        "##Exercício 3.3\n",
        "\n",
        "Repita o exercício 2 mas usando agora o calculando o gradiente usando o método backward() do pytorch. Confira se o primeiro valor do gradiente está de acordo com os valores anteriores. Execute essa próxima célula duas vezes. Os valores devem ser iguais.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMP4d5vtHtqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a106a4-a6b6-484f-cd99-2f88ef5543a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14., grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-28.])\n",
            "w = tensor([1.2800], grad_fn=<SubBackward0>)\n",
            "i = 1\n",
            "J= tensor(7.2576, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-20.1600])\n",
            "w = tensor([1.4816], grad_fn=<SubBackward0>)\n",
            "i = 2\n",
            "J= tensor(3.7623, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-14.5152])\n",
            "w = tensor([1.6268], grad_fn=<SubBackward0>)\n",
            "i = 3\n",
            "J= tensor(1.9504, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-10.4509])\n",
            "w = tensor([1.7313], grad_fn=<SubBackward0>)\n",
            "i = 4\n",
            "J= tensor(1.0111, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-7.5247])\n",
            "w = tensor([1.8065], grad_fn=<SubBackward0>)\n",
            "i = 5\n",
            "J= tensor(0.5241, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-5.4178])\n",
            "w = tensor([1.8607], grad_fn=<SubBackward0>)\n",
            "i = 6\n",
            "J= tensor(0.2717, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-3.9008])\n",
            "w = tensor([1.8997], grad_fn=<SubBackward0>)\n",
            "i = 7\n",
            "J= tensor(0.1409, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-2.8086])\n",
            "w = tensor([1.9278], grad_fn=<SubBackward0>)\n",
            "i = 8\n",
            "J= tensor(0.0730, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-2.0222])\n",
            "w = tensor([1.9480], grad_fn=<SubBackward0>)\n",
            "i = 9\n",
            "J= tensor(0.0379, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-1.4560])\n",
            "w = tensor([1.9626], grad_fn=<SubBackward0>)\n",
            "i = 10\n",
            "J= tensor(0.0196, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-1.0483])\n",
            "w = tensor([1.9730], grad_fn=<SubBackward0>)\n",
            "i = 11\n",
            "J= tensor(0.0102, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-0.7548])\n",
            "w = tensor([1.9806], grad_fn=<SubBackward0>)\n",
            "i = 12\n",
            "J= tensor(0.0053, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-0.5434])\n",
            "w = tensor([1.9860], grad_fn=<SubBackward0>)\n",
            "i = 13\n",
            "J= tensor(0.0027, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-0.3913])\n",
            "w = tensor([1.9899], grad_fn=<SubBackward0>)\n",
            "i = 14\n",
            "J= tensor(0.0014, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-0.2817])\n",
            "w = tensor([1.9928], grad_fn=<SubBackward0>)\n",
            "i = 15\n",
            "J= tensor(0.0007, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-0.2028])\n",
            "w = tensor([1.9948], grad_fn=<SubBackward0>)\n",
            "i = 16\n",
            "J= tensor(0.0004, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-0.1460])\n",
            "w = tensor([1.9962], grad_fn=<SubBackward0>)\n",
            "i = 17\n",
            "J= tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-0.1052])\n",
            "w = tensor([1.9973], grad_fn=<SubBackward0>)\n",
            "i = 18\n",
            "J= tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-0.0757])\n",
            "w = tensor([1.9981], grad_fn=<SubBackward0>)\n",
            "i = 19\n",
            "J= tensor(5.3059e-05, grad_fn=<AddBackward0>)\n",
            "None\n",
            "grad = tensor([-0.0545])\n",
            "w = tensor([1.9986], grad_fn=<SubBackward0>)\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1, requires_grad=True)\n",
        "\n",
        "history_J = []\n",
        "history_i = []\n",
        "\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    print('J=', J)\n",
        "    print(w.grad)\n",
        "    if w.grad: w.grad.zero_()\n",
        "    J.backward()\n",
        "    grad = w.grad\n",
        "    print('grad =',grad)\n",
        "    w = w - learning_rate * grad\n",
        "    print('w =', w)\n",
        "    w.retain_grad()\n",
        "\n",
        "    history_J.append(J.item())\n",
        "    history_i.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plote o gráfico da loss J pela iteração i\n",
        "plt.plot(history_i, history_J)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('J')\n",
        "plt.title('Loss Function for each iteration')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ytJd3x8G8-vH",
        "outputId": "ddda9eb4-fc2b-478d-d8f0-ba0729ec78e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhc9X3v8fd3NLIkW7JlWbK8WwZLNsZsrsIaCGAKNiVA+vRJSUgaElqa3pClTW4KIdttk9yUpElolqa+gZCkhNASSLi5OEBCgLAEMA6LF7xgvNuSbGNZXiRr+d4/zpEZixlJtjRzNHM+r+eZZ8425/edo6PvOed3fvM75u6IiEh8JKIOQEREckuJX0QkZpT4RURiRolfRCRmlPhFRGJGiV9EJGaU+KUgmNl+MzshC+udY2YvmlmbmX1suNc/HMyszszczJKDXP77Zva5bMc1QAwrzezCKGOIMyX+AmJmG83skgjKvdPMDofJt/f1l1ks7zEz++vUae5e7u4bslDcp4HfuXuFu/9bFtafc+7+YXf/ZwAzu9DMtmazvHD/+FKfGE5298eyWa5kpsQvw+XWMPn2vu6JOqBhMhNYeTwfHOwZeD6Lw3csREr8MWBmJWb2LTPbHr6+ZWYl4bxqM/uVme01sz1m9nszS4Tz/tHMtoXVHGvMbOExlnvUmV7fs8vwCuVTZvaymbWa2T1mVpoy/6qwmmWfmb1mZovM7MvA+cB3wiuL74TLupnNDofHmdmPzazFzDaZ2WdTvtN1ZvakmX3dzN4ws9fNbHGG+B8FLkopq2EQ637KzL5pZruBL6ZZZ8LMbgq/z24z+y8zq0qZ/99mtjPcHk+Y2ckp88rM7F/DclvD71GWsvprzWyzme0ys1sG+ruY2RhgKTAl5UptSn8xplQrXW9mm4FH+4vbzG4ArgU+Ha7//6b87S8Jh/vbPy80s61m9kkzazazHWb2wUzfTQZHiT8ebgHOBk4HTgPOBD4bzvsksBWoAWqBzwBuZnOAG4G3uXsFcBmwMQuxvRtYBMwCTgWuAzCzM4EfA/8TqAQuADa6+y3A74EbwyuLG9Os89vAOOAE4B3AXwGpyeIsYA1QDdwK3G5m1ncl7n5xn7LWDnLdGwi25ZfTxPZR4Orws1OAN4DvpsxfCtQDE4HlwF0p874O/AlwLlBFUA3VkzL/7cAcYCHweTM7KU35qd/vALAY2J5ypbZ9EDESzjuJYL/IGLe7LwmHe68I35kmlP72T4BJBNt8KnA98F0zG9/fd5MBuLteBfIiSMyXpJn+GnB5yvhlBEkU4J+AXwKz+3xmNtAMXAIUD1DunUA7sDd87UqZ/qWU5S4EtvaJ930p47cC3w+H/wP4ZobyHgP+us80D2MuAg4D81Lm/S3wWDh8HbA+Zd7o8LOTBiprkOvePMC2Wg0sTBmfDHQCyTTLVoaxjSM4STsEnJZmubpwuWkp054Drunn7/WldH+TgWJMKeuEfr7jkbjT7Qd991X63z8vDL93MmV+M3B21P9v+fzSGX88TAE2pYxvCqcBfA1YDzxsZhvM7CYAd18PfIKguqLZzH5mZlPI7OvuXhm+qo8htp0pwweB8nB4OkFCOFbVQDFv/b5T05Xp7gfDwXIGNph1bxlgHTOB+8Oqtb0ESbYbqDWzIjP7aljFso83r7Cqw1cp/W+TTNvyWGWMMWWZI99zgLgHo7/9E2C3u3eljA/luwmq6omL7QT/zL1mhNNw9zZ3/6S7nwBcCfyDhXX57v5Td397+FkH/uUYyz1AcEbda9IxfHYLcGKGef11KbuL4Oy07/fddgxlD2XdA3V3uwVYnHKQrHT3UnffBrwXuIrgKmscwdk1gIVlt5N5mxyvdPH2F2O6z/UXd6YyUmXcPyU7lPgLT7GZlaa8ksDdwGfNrMbMqoHPA/8JYGZXmNnssI67leDMrseC9usXhzfZ2gkut3vSF5nRi8DlZlZlZpMIriAG63bgg2a2MLzZONXM5obzmgjq2N/C3buB/wK+bGYVZjYT+Ife7zsUw7Tu74efnwkQ/k2uCudVAB3AboID5ldSyu4B7gC+Ed6ALTKzc3pvgg5BEzDBzMYNMsZ0MsadUkZ/v7HIuH9KdijxF54HCZJ07+uLwJeAZcDLwCsEN996W9vUA78B9gPPAN9z998BJcBXCc40dxLctLv5GGP5CfASwaX/w8Cgm3i6+3MEN02/SXBAepw3zwpvA/7CglY56drWf5TgamMD8CTwU4KkORyGuu7bgAcIqtbagD8Q3BCG4Gb2JoIriFXhvFSfIvj7PQ/sIbgCG9L/sLu/SpB4N4RVO1MGiDGdgeK+HZgXrv8XaT7f3/4pWWDhzRIREYkJnfGLiMSMEr+ISMwo8YuIxIwSv4hIzORFB0vV1dVeV1cXdRgiInnlhRde2OXuNX2n50Xir6urY9myZVGHISKSV8xsU7rpquoREYkZJX4RkZhR4hcRiRklfhGRmFHiFxGJmawlfjO7I3xU2oo08z4ZPr7tWPptFxGRYZDNM/47CR6pdxQzmw5cCmzOYtkiIpJB1hK/uz9B0HVsX98keFZo1rsFffTVJr732PpsFyMikldyWscfPsxhm7u/NIhlbzCzZWa2rKWl5bjKe3r9bm77zTq6e9T1tIhIr5wlfjMbDXyG4Ok6A3L3Je7e6O6NNTVv+cXxoDTUVtDR1cOWPQcHXlhEJCZyecZ/IjALeMnMNgLTgOXhI/myor42eB7z2qa2bBUhIpJ3cpb43f0Vd5/o7nXuXgdsBRa4+85slVlfWwHAuub92SpCRCTvZLM5590Ez3CdY2Zbzez6bJWVSXlJkqmVZazZqTN+EZFeWeud093fM8D8umyVnaq+tlxVPSIiKQr+l7sNtRVsaDlAV3dP1KGIiIwIBZ/46yeWc7i7h01q2SMiAsQg8Tf03uBVdY+ICBCDxD97Ym+TTrXsERGBGCT+MSVJpo0v0w1eEZFQwSd+CKp71umMX0QEiFHi37BrP51q2SMiEpfEX05nt7Np94GoQxERiVxMEn/Qskc3eEVEYpL4T6wpx0ydtYmIQEwSf9moImZUjdYNXhERYpL4AeonVuiMX0SEGCX+htpyXt91gMNdatkjIvEWo8RfQVeP8/outewRkXiLTeLX07hERAKxSfwn1pSTMHXWJiISm8RfWlzEzAlj1JZfRGIvNokfgr751zbrjF9E4i1Wib+htoJNuw/S0dUddSgiIpHJ5sPW7zCzZjNbkTLta2b2qpm9bGb3m1lltspPp2FSBd09zoYWtewRkfjK5hn/ncCiPtMeAea7+6nAWuDmLJb/Fg1q2SMikr3E7+5PAHv6THvY3bvC0T8A07JVfjqzqsdQlDB13SAisRZlHf+HgKWZZprZDWa2zMyWtbS0DEuBJcki6iaM1hm/iMRaJInfzG4BuoC7Mi3j7kvcvdHdG2tqaoat7IbaCtY164xfROIr54nfzK4DrgCudXfPdfn1tRVs2n2A9k617BGReMpp4jezRcCngSvd/WAuy+7VUFtOj8NrLTrrF5F4ymZzzruBZ4A5ZrbVzK4HvgNUAI+Y2Ytm9v1slZ/Jm0/jUj2/iMRTMlsrdvf3pJl8e7bKG6y6CWNIJkxdN4hIbMXql7sAo5IJZlWPUWdtIhJbsUv8EFT36IxfROIqlom/vracLW8c5NBhtewRkfiJZeKfU1uBO6xXe34RiaFYJv56tewRkRiLZeKvmzCaUUUJ9c0vIrEUy8SfLEpwQs0YddYmIrEUy8QPQXWPqnpEJI5im/gbJpaz9Y1DHOjoGnhhEZECEtvE33uDVy17RCRuYpv49TQuEYmr2Cb+mRPGMCqZUN/8IhI7sU38RQnjxJpy1uzUGb+IxEtsEz8E1T3qrE1E4ibmib+C7a3ttLV3Rh2KiEjOxDrx108MbvCqnl9E4iTWiX/OpKBJp6p7RCROYp34p48fTWlxQn3zi0isxDrxJxLG7InlassvIrES68QP0DCxQp21iUisZC3xm9kdZtZsZitSplWZ2SNmti58H5+t8gervraCnfvaaT2klj0iEg/ZPOO/E1jUZ9pNwG/dvR74bTgeqd6uG9arb34RiYmsJX53fwLY02fyVcCPwuEfAVdnq/zBajjyNC5V94hIPOS6jr/W3XeEwzuB2kwLmtkNZrbMzJa1tLRkLaCplWWUFRfpBq+IxEZkN3fd3QHvZ/4Sd29098aampqsxZFIGPW15brBKyKxkevE32RmkwHC9+Ycl59W/UQ9jUtE4iPXif8B4APh8AeAX+a4/LQaastpbutg78HDUYciIpJ12WzOeTfwDDDHzLaa2fXAV4E/NbN1wCXheOR0g1dE4iSZrRW7+3syzFqYrTKPV8Ok3sTfxpmzqiKORkQku2L/y12AKeNKKS9JqrM2EYkFJX7ArLfPHlX1iEjhU+IPNdSWs06/3hWRGFDiDzXUVrBr/2H2HFDLHhEpbEr8ofraN2/wiogUMiX+UG9nbbrBKyKFTok/NGlsKRUlSd3gFZGCp8QfMgv67FFVj4gUOiX+FA21Faxr1hm/iBQ2Jf4U9bUV7DlwmF37O6IORUQka5T4U/Te4FV1j4gUMiX+FEc6a9upxC8ihUuJP8XEihLGlRWzVvX8IlLAlPhTmFnQdYOqekSkgCnx91FfW8Hapv0ET4YUESk8Svx9NEwsp/VQJy1tatkjIoVJib8PPY1LRAqdEn8f6qxNRAqdEn8f1eWjGD+6WH3zi0jBiiTxm9nfm9lKM1thZnebWWkUcaQT9NlToaoeESlYOU/8ZjYV+BjQ6O7zgSLgmlzH0Z+GsLM2tewRkUIUVVVPEigzsyQwGtgeURxpNdRW0NbeRdM+tewRkcKT88Tv7tuArwObgR1Aq7s/3Hc5M7vBzJaZ2bKWlpacxlg/UTd4RaRwRVHVMx64CpgFTAHGmNn7+i7n7kvcvdHdG2tqanIaozprE5FCFkVVzyXA6+7e4u6dwH3AuRHEkdGE8hKqy0exTjd4RaQARZH4NwNnm9loMzNgIbA6gjj6VT+xgjU64xeRAhRFHf+zwL3AcuCVMIYluY5jIA215axvVp89IlJ4klEU6u5fAL4QRdmDVV9bwf6OLra3tjO1sizqcEREho1+uZtBg7puEJECpcSfQW/LHvXNLyKFRok/g8rRo6ipKFHXDSJScJT4+6GncYlIIVLi78fcSWN5dWcbhw53Rx2KiMiwUeLvx8VzJ9LR1cPja5ujDkVEZNgo8ffjrFlVjB9dzNIVO6MORURk2Cjx9yNZlOBP59Xy6OpmOrpU3SMihSFj4jezNjPbl+HVYmZ/MLOFuQw2CovnT6ato4un1u+KOhQRkWGR8Ze77l6RaZ6ZFQHzgbvC94J17uwJVJQkWfrKTi6eWxt1OCIiQ3ZcVT3u3u3uLwHfHuZ4RpySZBELT5rII6ub6OzuiTocEZEhG1Idv7v/x3AFMpItmj+ZvQc7eXbDnqhDEREZMt3cHYR3NNRQVlzE0hU7og5FRGTIlPgHoWxUERfNreGhlU1096ibZhHJb0r8g7Ro/mR27e/ghU1vRB2KiMiQKPEP0sVzJzIqmVB1j4jkPSX+QSovSXJBfQ2/XrGTHlX3iEgeU+I/BovnT2JHazsvbd0bdSgiIsdNif8YXHJSLcmE8Wv13SMieSySxG9mlWZ2r5m9amarzeycKOI4VuNGF3Pu7GqWrtiph7CLSN6K6oz/NuDX7j4XOA1YHVEcx2zx/Els3nOQVTv2RR2KiMhxyXniN7NxwAXA7QDuftjd86bS/NJ5tSQMVfeISN6K4ox/FtAC/NDM/mhmPzCzMX0XMrMbzGyZmS1raWnJfZQZTCgv4cxZVeqjX0TyVhSJPwksAP7d3c8ADgA39V3I3Ze4e6O7N9bU1OQ6xn4tnj+Z9c37Wd+s5/GKSP6JIvFvBba6+7Ph+L0EB4K8cdnJkwBY+orO+kUk/+Q88bv7TmCLmc0JJy0EVuU6jqGYNK6UBTMqVd0jInkpqlY9HwXuMrOXgdOBr0QUx3G7/JTJrNqxj027D0QdiojIMYkk8bv7i2H9/anufrW7513PZ0eqe3TWLyJ5Rr/cPU7Tq0ZzytRxSvwikneU+Idg0fxJvLRlL9v3Hoo6FBGRQVPiH4LF84PqHv2YS0TyiRL/EJxQU86c2golfhHJK0r8Q7Ro/iSe37SH5rb2qEMRERkUJf4hWnzKJNzh4ZVNUYciIjIoSvxDNKe2glnVY1TdIyJ5Q4l/iMyMRfMn8cyG3bxx4HDU4YiIDEiJfxhcPn8y3T3OI6tV3SMiI58S/zCYP3Us08aXqbpHRPKCEv8wMDMWnTyJ369rYV97Z9ThiIj0S4l/mCw+ZRKd3c6jq5ujDkVEpF9K/MPkjOnjqR1bwtIVO6IORUSkX0r8wySRMC47eRKPr23h4OGuqMMREclIiX8YLZo/ifbOHh5bM3KeESwi0pcS/zA6s66KqjGj1FWziIxoSvzDKFmU4NJ5tTy6uon2zu6owxERSUuJf5gtmj+JA4e7eXLdrqhDERFJS4l/mJ17YjVjS5Oq7hGRESuyxG9mRWb2RzP7VVQxZMOoZIJL5tXym9VNdHb3RB2OiMhbRHnG/3FgdYTlZ83i+ZNpPdTJM6/tjjoUEZG3iCTxm9k04M+AH0RRfradX1/NmFFF+jGXiIxIUZ3xfwv4NJCxLsTMbjCzZWa2rKUlv9rFlxYXcdHciTy8sonuHo86HBGRo+Q88ZvZFUCzu7/Q33LuvsTdG929saamJkfRDZ/F8yez+8Bhnnt9T9ShiIgcJYoz/vOAK81sI/Az4GIz+88I4siqC+fUUJJM8GtV94jICJPzxO/uN7v7NHevA64BHnX39+U6jmwbU5LkHQ01PLhiJ4cO68dcIjJyqB1/Fl3/9lm0tHVw22/XRR2KiMgRkSZ+d3/M3a+IMoZsOuuECby7cRo/+P0GXt25L+pwREQAnfFn3c2LT2JsWTE33/cKPWrhIyIjgBJ/lo0fM4rPXXESf9y8l7ue2xx1OCIiSvy5cPXpUzlv9gRuXfoqzfvaow5HRGJOiT8HzIwvXX0KHd09/K9frYo6HBGJOSX+HJlVPYaPXTyb//fyDn73qh7ILiLRUeLPoRsuOJHZE8v57C9W6Lm8IhIZJf4cGpVM8JV3ncK2vYe47Tdq2y8i0VDiz7EzZ1Vxzdum84MnX2fVdrXtF5HcU+KPwE2L5zJ+dDE33/+Keu8UkZxT4o9A5ehRfO6Keby0ZS93Pbsp6nBEJGaU+CNy5WlTOL++mlt/vYYmte0XkRxS4o9I0LZ/Pp3dPXzxgZVRhyMiMaLEH6GZE8bwsYX1LF2xk9+saoo6HBGJCSX+iP3N+SfQUFvOFx5YyYEOte0XkexT4o9Yatv+bz6yNupwRCQGlPhHgMa6Kt571gzueOp1VmxrjTocESlwSvwjxD9eNpeqMSV8Rm37RSTLlPhHiHGji/n8O+fx8tZWfvLMxqjDEZECpsQ/grzz1Mlc0FDD1x5aw47WQ1GHIyIFSol/BDEzvnz1fLrd1bZfRLIm54nfzKab2e/MbJWZrTSzj+c6hpFsetVoPr6wgYdWNvHwyp1RhyMiBSiKM/4u4JPuPg84G/iImc2LII4R66/Pn8XcSRV84YGV7FfbfhEZZjlP/O6+w92Xh8NtwGpgaq7jGMmKixJ8+V2nsHNfO19/aE3U4YhIgYm0jt/M6oAzgGfTzLvBzJaZ2bKWlpZchxa5P5k5nvefPZM7n97I/35wtZp4isiwSUZVsJmVAz8HPuHub3kiibsvAZYANDY2xjLrfe6KebjDfzyxgXXN+7ntmtOpKC2OOiwRyXORnPGbWTFB0r/L3e+LIoZ8UFyU4J+vns8/X3Uyj69t4c+/9zSbdx+MOiwRyXNRtOox4HZgtbt/I9fl56P3n1PHTz50Js1tHVz53Sd55rXdUYckInksijP+84D3Axeb2Yvh6/II4sgr586u5pcfOY8JY0bx/tuf5afPbo46JBHJUzmv43f3JwHLdbmFoK56DPd/5Dw+dvcf+cz9r7C2qY3P/tlJJIv0OzwRGTxljDwztrSY2z/wNv7m/Fnc+fRGrvvh87Qe7Iw6LBHJI0r8eagoYdzyZ/O49S9O5dnXd3P1957itZb9UYclInlCiT+PvbtxOj/9m7PZd6iTq7/7FI+vjd/vHUTk2Cnx57m31VXxyxvPY2plGR/84XPc8eTruMfyZw8iMkhK/AVg2vjR/PzvzuWSk2r5p1+t4ub7XuFwV0/UYYnICKXEXyDGlCT5/vv+hBsvms3Pnt/C+25/lj0HDkcdloiMQEr8BSSRMD512Rxuu+Z0Xtqylyu/8ySv7nxLbxgiEnNK/AXoqtOn8l9/ew6Hu3p457ef5O/veZGXtuyNOiwRGSEsH24ENjY2+rJly6IOI+8072vne4+9xr0vbGV/RxdnzKjkunPrWDx/MqOSOuaLFDoze8HdG98yXYm/8LW1d/LzF7byo2c28fquA0ysKOHas2by3rNmUFNREnV4IpIlSvxCT4/z+LoW7nxqI4+vbWFUUYIrTp3MdefVceq0yqjDE5FhlinxR9Yfv+ReImFcNGciF82ZyGst+/nJM5v472VbuO+P21gwo5LrzpvF4vmTKFbfPyIFTWf8MdfW3sm9L2zlR09vZOPug9SODaqB3nOmqoFE8p2qeqRfPT3O42tb+OHTG3mitxrotMlce9YMTp1WqasAkTykqh7pVyJhXDR3IhfNncj65v38+JmN/PyFrdy3fBulxQlOnVrJGTMrWTBjPAtmjNfVgEge0xm/ZLSvvZPH17SwfPMbLN+8l1XbW+nsDvaX6VVlRw4CC2aMZ+7kCl0ViIwwquqRIWvv7Gbl9laWb9obHgzeoGlfB0BwVTCt94qgkgUzx1NdrqsCkSgp8cuwc3e2t7azfNMbaa8KZlSN5pRp45g2vowp48qYUlnG5HGlTK0so3J0McHjl0UkW1THL8POzJhaWcbUyjLeedoUILgqWLGtNTgQbNrLim2tPLKyicPdR/cWWlqcYEpl7wGhlMnjgvVMriw9Mr1sVFEUX0uk4EWS+M1sEXAbUAT8wN2/GkUcMvxKi4torKuisa7qyLSeHmf3gcPsaD3E9r2H2La3nR17D7G99RDb97bz2JoWWvZ30Pfic/zoYmrHljK2rJixpUkqSoupKE0yNnyvKC1mbNnR03uXKy1O6IpCJIOcJ34zKwK+C/wpsBV43swecPdVuY5FciORMGoqSqipKMn4C+HDXT007Wtne8oBYfveQzTt66CtvZNte9tpa2+jrb2LtvZOegaooSwuMipKiykvSVJanGBUMkFJsoiSZCJ8FVFSnDKcTITjKcsUFzGqKEGyyChKGMmEkUwkKCoKhot6xxMp40XBtN7x3pcZJMzCV3C1VJQIhhOWfr5ItkRxxn8msN7dNwCY2c+AqwAl/hgblUwwvWo006tGD7isu3PgcDdt7Z20tXex71D43t7JvvDA0Dt9f0cXh7t66OjqoaOrm47OHtrau4Lhrh46Ons43N1DR2cw3jXQESWHihKGAWZgBAeHo4YJDhAGkHIASZ1uvTOPrIcjw8Ec6zP+1oNO6uhRw/Sz3FHT+z+IDXiIG+IxcKiH0KgPwl951ymcOatq4AWPQRSJfyqwJWV8K3BW34XM7AbgBoAZM2bkJjLJC2ZGeUmS8pIkk8cN77q7unsPBG8eLLp7nK4ep6vbw+GeI9PefO+hs/vo8d7lexx63HF/c7i7x/FwON38ntTPAe7gBJ9xD9/7TIfe9aQsG36vYL6nDKe8p0w/evk35/Hmx/sOhst72nkDtR0Z6DA71MYnQz6Mj4DzgDElw3+va8Te3HX3JcASCFr1RByOxESyKEGyKMHoUVFHIpI9UfziZhswPWV8WjhNRERyIIrE/zxQb2azzGwUcA3wQARxiIjEUs6rety9y8xuBB4iaM55h7uvzHUcIiJxFUkdv7s/CDwYRdkiInGnXrVERGJGiV9EJGaU+EVEYkaJX0QkZvKiW2YzawE2HefHq4FdwxjOcFN8Q6P4hkbxDd1IjnGmu9f0nZgXiX8ozGxZuv6oRwrFNzSKb2gU39DlQ4x9qapHRCRmlPhFRGImDol/SdQBDEDxDY3iGxrFN3T5EONRCr6OX0REjhaHM34REUmhxC8iEjMFk/jNbJGZrTGz9WZ2U5r5JWZ2Tzj/WTOry2Fs083sd2a2ysxWmtnH0yxzoZm1mtmL4evzuYovLH+jmb0Slr0szXwzs38Lt9/LZrYgh7HNSdkuL5rZPjP7RJ9lcrr9zOwOM2s2sxUp06rM7BEzWxe+j8/w2Q+Ey6wzsw/kML6vmdmr4d/vfjNL+wDkgfaFLMb3RTPblvI3vDzDZ/v9X89ifPekxLbRzF7M8Nmsb78h8/CRb/n8Iuje+TXgBGAU8BIwr88y/wP4fjh8DXBPDuObDCwIhyuAtWniuxD4VYTbcCNQ3c/8y4GlBI8wPRt4NsK/9U6CH6ZEtv2AC4AFwIqUabcCN4XDNwH/kuZzVcCG8H18ODw+R/FdCiTD4X9JF99g9oUsxvdF4FOD+Pv3+7+erfj6zP9X4PNRbb+hvgrljP/IA9zd/TDQ+wD3VFcBPwqH7wUWWo6eouzuO9x9eTjcBqwmePZwPrkK+LEH/gBUmtnkCOJYCLzm7sf7S+5h4e5PAHv6TE7dx34EXJ3mo5cBj7j7Hnd/A3gEWJSL+Nz9YXfvCkf/QPD0u0hk2H6DMZj/9SHrL74wb7wbuHu4y82VQkn86R7g3jexHlkm3PlbgQk5iS5FWMV0BvBsmtnnmNlLZrbUzE7OaWDBY6UfNrMXwgfd9zWYbZwL15D5Hy7K7QdQ6+47wuGdQG2aZUbKdvwQwRVcOgPtC9l0Y1gVdUeGqrKRsP3OB5rcfV2G+VFuv0EplMSfF8ysHPg58Al339dn9nKC6ovTgG8Dv8hxeG939wXAYuAjZnZBjssfUPioziuB/04zO+rtdxQPrvlHZFtpM7sF6ALuyrBIVPvCvwMnAqcDOwiqU0ai99D/2f6I/18qlMQ/mAe4H1nGzJLAOGB3TqILyiwmSPp3uft9fee7+z533x8OPwgUmxaKZi0AAAOsSURBVFl1ruJz923hezNwP8EldarBbONsWwwsd/emvjOi3n6hpt7qr/C9Oc0ykW5HM7sOuAK4Njw4vcUg9oWscPcmd+929x7g/2QoN+rtlwT+HLgn0zJRbb9jUSiJfzAPcH8A6G1B8RfAo5l2/OEW1gneDqx2929kWGZS7z0HMzuT4G+TkwOTmY0xs4reYYKbgCv6LPYA8Fdh656zgdaUao1cyXimFeX2S5G6j30A+GWaZR4CLjWz8WFVxqXhtKwzs0XAp4Er3f1ghmUGsy9kK77Ue0bvylDuYP7Xs+kS4FV335puZpTb75hEfXd5uF4ErU7WEtzxvyWc9k8EOzlAKUEVwXrgOeCEHMb2doLL/peBF8PX5cCHgQ+Hy9wIrCRopfAH4NwcxndCWO5LYQy92y81PgO+G27fV4DGHP99xxAk8nEp0yLbfgQHoB1AJ0E98/UE94x+C6wDfgNUhcs2Aj9I+eyHwv1wPfDBHMa3nqB+vHcf7G3lNgV4sL99IUfx/STct14mSOaT+8YXjr/lfz0X8YXT7+zd51KWzfn2G+pLXTaIiMRMoVT1iIjIICnxi4jEjBK/iEjMKPGLiMSMEr+ISMwo8UusmNn+8L3OzN47zOv+TJ/xp4dz/SLDRYlf4qoOOKbEH/5qsz9HJX53P/cYYxLJCSV+iauvAueHfab/vZkVhf3VPx92Eva3cKSf/9+b2QPAqnDaL8IOuFb2dsJlZl8FysL13RVO6726sHDdK8J+2v8yZd2Pmdm9FvSTf1eueoyVeBvoDEakUN1E0Pf7FQBhAm9197eZWQnwlJk9HC67AJjv7q+H4x9y9z1mVgY8b2Y/d/ebzOxGdz89TVl/TtDx2GlAdfiZJ8J5ZwAnA9uBp4DzgCeH/+uKvEln/CKBSwn6InqRoMvsCUB9OO+5lKQP8DEz6+0aYnrKcpm8Hbjbgw7ImoDHgbelrHurBx2TvUhQBSWSVTrjFwkY8FF3P6rDNDO7EDjQZ/wS4Bx3P2hmjxH0A3W8OlKGu9H/pOSAzvglrtoIHoPZ6yHg78LuszGzhrB3xb7GAW+ESX8uwWMoe3X2fr6P3wN/Gd5HqCF4rN9zw/ItRI6Dzi4krl4GusMqmzuB2wiqWZaHN1hbSP/oxF8DHzaz1cAaguqeXkuAl81subtfmzL9fuAcgh4bHfi0u+8MDxwiOafeOUVEYkZVPSIiMaPELyISM0r8IiIxo8QvIhIzSvwiIjGjxC8iEjNK/CIiMfP/AWtCbN2H+XIyAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GulfYtzBMx2e"
      },
      "source": [
        "##Exercício 3.4\n",
        "\n",
        "Quais são as restrições na escolha dos valores de $\\Delta w$ no cálculo do gradiente por diferenças finitas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXQGEyvtiTAR"
      },
      "source": [
        "**Resposta:**\n",
        "\n",
        "O $\\Delta w$ indica a distancia entre amostras para o cálculo da diferenças finitas. Essa distância deve ser pequena o suficiente para possuir um erro adequado no resultado da derivada, porêm grande o suficiente para não acontecer o cancelamento caststrófico (aumento substancial no erro relativo). Um exemplo desse fenêmeno pode ser visto abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "J = J_func(w, x, y)\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "\n",
        "## Assumindo que o valor correto é -28\n",
        "true_grad = -28\n",
        "for delta_w in (1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8):\n",
        "  grad = (J_func(w+delta_w, x, y) - J_func(w-delta_w, x, y)) / (2*delta_w)\n",
        "  print(f'Erro para delta_w = {delta_w:.0e}: \\t{true_grad - grad.item():.4e}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcSs6DiQOpTS",
        "outputId": "2afa7043-ad71-4eed-f1b8-ae420ceb8cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro para delta_w = 1e-02: \t-2.6703e-05\n",
            "Erro para delta_w = 1e-03: \t8.2970e-04\n",
            "Erro para delta_w = 1e-04: \t-1.2207e-04\n",
            "Erro para delta_w = 1e-05: \t3.8025e-02\n",
            "Erro para delta_w = 1e-06: \t-3.4344e-01\n",
            "Erro para delta_w = 1e-07: \t1.0147e+01\n",
            "Erro para delta_w = 1e-08: \t-2.8000e+01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsrSF8GEiXk4"
      },
      "source": [
        "##Exercício 3.5\n",
        "\n",
        "Até agora trabalhamos com $w$ contendo apenas um parâmetro. Suponha agora que $w$ seja uma matriz com $N$ parâmetros e que o custo para executar $(x_i w - y_i)^2$ seja $O(N)$.\n",
        "> a) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método das diferencas finitas?\n",
        ">\n",
        "> b) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método do backpropagation?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Pna3bcicHj"
      },
      "source": [
        "Resposta (justifique):\n",
        "\n",
        "a) $O(N²)$ -> A função $J$ é o somatório de  $(x_i w - y_i)^2$, portanto a computação é N vezes o tamanho da matriz de X e y, ou seja $O(N)$ (sabendo que X e y não dependem de N). Para calulcar o método das diferenas finitas, necessita realizar essa operação duas vezes: $2 \\times O(N)$. Assintoticamente, é igual a $O(N)$.\n",
        "\n",
        "b) $O(N)$ -> O backpropagation tem a mesma complexidade do foward, uma vez que os gradientes já foram calculados. Desta forma, a complexidade é de $O(N)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35I5w8EZdjIo"
      },
      "source": [
        "##Exercício 3.6\n",
        "\n",
        "Qual o custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do treinamento de um classificador inicializado aleatoriamente?\n",
        "\n",
        "A equação da entropia cruzada é:\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j, $$\n",
        "Onde:\n",
        "\n",
        "- K é o número de classes;\n",
        "\n",
        "- $y_j=1$ se $j$ é a classe do exemplo (ground-truth), 0 caso contrário. Ou seja, $y$ é um vetor one-hot;\n",
        "\n",
        "- $p_j$ é a probabilidade predita pelo modelo para a classe $j$.\n",
        "\n",
        "A resposta tem que ser em função de uma ou mais das seguintes variáveis:\n",
        "\n",
        "- K = número de classes\n",
        "\n",
        "- B = batch size\n",
        "\n",
        "- D = dimensão de qualquer vetor do modelo\n",
        "\n",
        "- LR = learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTOphiVs6eN"
      },
      "source": [
        "**Resposta:**\n",
        "\n",
        "Considerando que cada classe tem a mesma probabilidade, $p_j = \\frac{1}{K}$, sendo $K$ o número de classes existentes. Portanto:\n",
        "\n",
        "$$L = - \\frac{1}{K} \\sum_{j=0}^{K-1} y_j \\log (p_j) $$\n",
        "$$L = - \\frac{1}{K} \\sum_{j=0}^{K-1} y_j \\log (\\frac{1}{K}) $$\n",
        "$$L = - \\frac{1}{K} \\sum_{j=0}^{K-1} y_j \\log (1) - \\log (K) $$\n",
        "$$L = \\frac{1}{K} \\sum_{j=0}^{K-1} y_j \\log (K) $$\n",
        "\n",
        "$$L = log(K)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UNdHqgSB6S9"
      },
      "source": [
        "Fim do notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "117px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}